{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd05cbf009346a6eab412f5ab14f605ed135c66531ba5ac86b5a8dd3e3f350b168a",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['final车场信息_上海停车_总车位_allMerged_type1_2021.03.25.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.03.26.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.03.29.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.03.30.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.03.31.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.04.01.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.04.02.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.04.03.csv', 'final车场信息_上海停车_总车位_allMerged_type1_2021.04.04.csv'] ['final车场信息_上海停车_总车位_allMerged_type2_2021.03.25.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.03.26.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.03.27.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.03.29.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.03.30.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.03.31.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.04.01.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.04.02.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.04.03.csv', 'final车场信息_上海停车_总车位_allMerged_type2_2021.04.04.csv']\n"
     ]
    }
   ],
   "source": [
    "file_name_affix = \"final车场信息_上海停车_总车位_allMerged_time_type\"\n",
    "file_name_list = [ i for i in os.listdir(\".\") if i.startswith(file_name_affix)]\n",
    "merge_type1_list = [i for i in os.listdir('.') if i.startswith(\"final车场信息_上海停车_总车位_allMerged_type1_2021\")]\n",
    "merge_type2_list = [i for i in os.listdir('.') if i.startswith(\"final车场信息_上海停车_总车位_allMerged_type2_2021\")]\n",
    "merge_type1_time_list = set([ i[i.find(\".\")+1:i.rfind(\".\")] for i in merge_type1_list ])\n",
    "merge_type2_time_list = set([ i[i.find(\".\")+1:i.rfind(\".\")] for i in merge_type2_list ])\n",
    "print(merge_type1_list, merge_type2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_all_merge_byDay_path = [\"final车场信息_上海停车_总车位_allMerged_timeAggregated_type1.csv\", \"final车场信息_上海停车_总车位_allMerged_timeAggregated_type2.csv\"]\n",
    "def getMerged(merge_name_list, merge_time_list, basic_all_merge_byDay_path, type):\n",
    "\n",
    "    def cutTime(id_df, time):\n",
    "        '''\n",
    "            每一个id_df 是表示某一个id下所爬取的时间\n",
    "            \n",
    "        '''\n",
    "        #print(\"id_df: \", id_df)\n",
    "        id_df[\"starttime\"] = pd.to_datetime(id_df[\"starttime\"])\n",
    "        # 根据每五分钟进行分割\n",
    "        id_df[\"starttime\"] = id_df[\"starttime\"].apply(lambda x: datetime.datetime(x.year, x.month, x.day, x.hour, x.minute//5*5))\n",
    "        # 截取7点 到 10点 的数据\n",
    "        # index 是表示数据位置的索引\n",
    "        index = id_df[\"starttime\"].apply(lambda x: True if (x.hour > 6 and x.hour < 22) else False)\n",
    "        #print(\"index: \", index)\n",
    "        \n",
    "        c = id_df[index]\n",
    "        c = c.reset_index(drop=True)\n",
    "        d = pd.DataFrame()\n",
    "        #print(\"c: \\n\", c)\n",
    "        if (len(c) != 0):\n",
    "            year = c.iloc[0][\"starttime\"].year\n",
    "            month = c.iloc[0][\"starttime\"].month\n",
    "            day = c.iloc[0][\"starttime\"].day\n",
    "            d[time] = pd.date_range(datetime.datetime(year, month, day, 7), datetime.datetime(year, month, day, 22), freq=\"5min\")\n",
    "            l = len(d[d[time].isin(c[\"starttime\"])])\n",
    "            d.loc[d[time].isin(c[\"starttime\"]),  [\"PERCENTAGE\"]] = c[\"PERCENTAGE\"][:l].to_numpy()\n",
    "            d[\"PARKING_ID2\"] = [str(id_df[\"PARKING_ID\"].iloc[0])+ \"_\" + str(i) for i in range(len(d))]\n",
    "            d[time] = d[\"PERCENTAGE\"]\n",
    "            #print(\"d: \", d)\n",
    "            d = d.drop(\"PERCENTAGE\", axis=1)\n",
    "            #print(\"finally d: \", d)\n",
    "            return d\n",
    "        else:\n",
    "            d = pd.DataFrame()\n",
    "            return d\n",
    "\n",
    "\n",
    "\n",
    "    # 对每个时间段的文件进行处理\n",
    "    for i in merge_time_list:\n",
    "        # 计算符合每个时间的文件\n",
    "        remain = [ k for k in merge_name_list if k.startswith(\"final车场信息_上海停车_总车位_allMerged_type{type}_2021.{a}\".format(type=type, a=i))]\n",
    "\n",
    "        base_path = basic_all_merge_byDay_path\n",
    "        for j in remain:\n",
    "            if base_path in os.listdir('.'):\n",
    "               data = pd.read_csv(j)\n",
    "               data = data.sort_values([\"PARKING_ID\", \"starttime\"], axis=0)\n",
    "               newData = data.groupby(\"PARKING_ID\").apply(cutTime, time=i)\n",
    "               base_data = pd.read_csv(base_path)\n",
    "               #base_data.index = base_data.index.droplevel()\n",
    "               print(\"newData: \", newData)\n",
    "               # 注意由于版本问题，\n",
    "               #newData.index = newData.index.droplevel()\n",
    "               #df = pd.concat([base_data, newData], axis=1)\n",
    "               df = pd.merge(base_data, newData ,how=\"outer\", on=\"PARKING_ID2\", validate=\"one_to_one\")\n",
    "               df = df.sort_index(axis=1)\n",
    "               df.to_csv(base_path, index = False)\n",
    "            else:\n",
    "               data = pd.read_csv(j)\n",
    "               # 按照名字与时间点进行排序\n",
    "               data = data.sort_values([\"PARKING_ID\", \"starttime\"], axis=0)\n",
    "\n",
    "               # 利用apply 对每个id对应的数据进行操作，返回进行切割后的数据\n",
    "               # 并将每一个数据进行拼接\n",
    "               newData = data.groupby(\"PARKING_ID\").apply(cutTime, time=i)\n",
    "               newData = newData.sort_index(axis=1)\n",
    "               newData.to_csv(base_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "newData:                     04.04        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0     0.10    cm31023000001_0\n",
      "              1     0.10    cm31023000001_1\n",
      "              2     0.10    cm31023000001_2\n",
      "              3     0.10    cm31023000001_3\n",
      "              4     0.10    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176    NaN  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178   0.93  xh31010400483_178\n",
      "              179    NaN  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[139189 rows x 2 columns]\n",
      "newData:                     03.31        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0     0.10    cm31023000001_0\n",
      "              1     0.10    cm31023000001_1\n",
      "              2     0.10    cm31023000001_2\n",
      "              3     0.10    cm31023000001_3\n",
      "              4      NaN    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176   0.94  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178   0.94  xh31010400483_178\n",
      "              179   0.94  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[139913 rows x 2 columns]\n",
      "newData:                     03.26        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0      0.1    cm31023000001_0\n",
      "              1      0.1    cm31023000001_1\n",
      "              2      0.1    cm31023000001_2\n",
      "              3      0.1    cm31023000001_3\n",
      "              4      0.1    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176    NaN  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178    NaN  xh31010400483_178\n",
      "              179    NaN  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[140275 rows x 2 columns]\n",
      "newData:                     04.02        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0      NaN    cm31023000001_0\n",
      "              1      NaN    cm31023000001_1\n",
      "              2      NaN    cm31023000001_2\n",
      "              3      NaN    cm31023000001_3\n",
      "              4      NaN    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176    NaN  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178    NaN  xh31010400483_178\n",
      "              179    NaN  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[139732 rows x 2 columns]\n",
      "newData:                     03.25        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0      NaN    cm31023000001_0\n",
      "              1      NaN    cm31023000001_1\n",
      "              2      NaN    cm31023000001_2\n",
      "              3      NaN    cm31023000001_3\n",
      "              4      NaN    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176    NaN  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178    NaN  xh31010400483_178\n",
      "              179   0.86  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[140456 rows x 2 columns]\n",
      "newData:                     04.03        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0     0.72    cm31023000001_0\n",
      "              1     0.72    cm31023000001_1\n",
      "              2     0.72    cm31023000001_2\n",
      "              3     0.72    cm31023000001_3\n",
      "              4      NaN    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176    NaN  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178    NaN  xh31010400483_178\n",
      "              179    NaN  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[139370 rows x 2 columns]\n",
      "newData:                     03.30        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0     0.10    cm31023000001_0\n",
      "              1     0.10    cm31023000001_1\n",
      "              2     0.10    cm31023000001_2\n",
      "              3     0.10    cm31023000001_3\n",
      "              4     0.10    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176    NaN  xh31010400483_176\n",
      "              177    NaN  xh31010400483_177\n",
      "              178    NaN  xh31010400483_178\n",
      "              179   0.86  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[139913 rows x 2 columns]\n",
      "newData:                     03.29        PARKING_ID2\n",
      "PARKING_ID                                 \n",
      "cm31023000001 0      NaN    cm31023000001_0\n",
      "              1      NaN    cm31023000001_1\n",
      "              2      NaN    cm31023000001_2\n",
      "              3      NaN    cm31023000001_3\n",
      "              4      NaN    cm31023000001_4\n",
      "...                  ...                ...\n",
      "xh31010400483 176   0.88  xh31010400483_176\n",
      "              177   0.88  xh31010400483_177\n",
      "              178   0.89  xh31010400483_178\n",
      "              179   0.89  xh31010400483_179\n",
      "              180    NaN  xh31010400483_180\n",
      "\n",
      "[139913 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "getMerged(merge_type1_list, merge_type1_time_list, basic_all_merge_byDay_path[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "newData:                  04.01  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0      NaN     CM-002_0\n",
      "           1      NaN     CM-002_1\n",
      "           2      NaN     CM-002_2\n",
      "           3      NaN     CM-002_3\n",
      "           4      NaN     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178    NaN  XHZ-026_178\n",
      "           179   0.46  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[76020 rows x 2 columns]\n",
      "newData:                  04.04  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0      1.0     CM-002_0\n",
      "           1      1.0     CM-002_1\n",
      "           2      1.0     CM-002_2\n",
      "           3      1.0     CM-002_3\n",
      "           4      1.0     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178    NaN  XHZ-026_178\n",
      "           179    NaN  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[75477 rows x 2 columns]\n",
      "newData:                  03.31  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0     0.90     CM-002_0\n",
      "           1     0.90     CM-002_1\n",
      "           2     0.90     CM-002_2\n",
      "           3     0.90     CM-002_3\n",
      "           4     1.00     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176   0.42  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178   0.42  XHZ-026_178\n",
      "           179   0.42  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[76020 rows x 2 columns]\n",
      "newData:                  03.26  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0     0.70     CM-002_0\n",
      "           1     0.70     CM-002_1\n",
      "           2     0.70     CM-002_2\n",
      "           3     0.70     CM-002_3\n",
      "           4     0.70     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178   0.54  XHZ-026_178\n",
      "           179    NaN  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[76382 rows x 2 columns]\n",
      "newData:                  04.02  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0      NaN     CM-002_0\n",
      "           1      NaN     CM-002_1\n",
      "           2      NaN     CM-002_2\n",
      "           3      NaN     CM-002_3\n",
      "           4      NaN     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178    NaN  XHZ-026_178\n",
      "           179    NaN  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[78554 rows x 2 columns]\n",
      "newData:                  03.25  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0      NaN     CM-002_0\n",
      "           1      NaN     CM-002_1\n",
      "           2      NaN     CM-002_2\n",
      "           3      NaN     CM-002_3\n",
      "           4      NaN     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178    NaN  XHZ-026_178\n",
      "           179   0.33  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[76382 rows x 2 columns]\n",
      "newData:                  04.03  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0      0.6     CM-002_0\n",
      "           1      0.6     CM-002_1\n",
      "           2      0.6     CM-002_2\n",
      "           3      0.6     CM-002_3\n",
      "           4      0.6     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178    NaN  XHZ-026_178\n",
      "           179    NaN  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[75477 rows x 2 columns]\n",
      "newData:                  03.30  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0     1.00     CM-002_0\n",
      "           1     1.00     CM-002_1\n",
      "           2     1.00     CM-002_2\n",
      "           3     0.90     CM-002_3\n",
      "           4     0.80     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176    NaN  XHZ-026_176\n",
      "           177    NaN  XHZ-026_177\n",
      "           178    NaN  XHZ-026_178\n",
      "           179   0.38  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[76020 rows x 2 columns]\n",
      "newData:                  03.29  PARKING_ID2\n",
      "PARKING_ID                        \n",
      "CM-002     0      NaN     CM-002_0\n",
      "           1      NaN     CM-002_1\n",
      "           2      NaN     CM-002_2\n",
      "           3      NaN     CM-002_3\n",
      "           4      NaN     CM-002_4\n",
      "...               ...          ...\n",
      "XHZ-026    176   0.38  XHZ-026_176\n",
      "           177   0.38  XHZ-026_177\n",
      "           178   0.38  XHZ-026_178\n",
      "           179   0.42  XHZ-026_179\n",
      "           180    NaN  XHZ-026_180\n",
      "\n",
      "[76201 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "getMerged(merge_type2_list, merge_type2_time_list, basic_all_merge_byDay_path[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-12-5f4d32fdd6c7>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[j] = m\n",
      "        03.25  03.26  03.29  03.30  03.31  04.01  04.02  04.03  04.04  \\\n",
      "0       0.224   0.10  0.224   0.10   0.10  0.224  0.224   0.72   0.10   \n",
      "1       0.224   0.10  0.224   0.10   0.10  0.224  0.224   0.72   0.10   \n",
      "2       0.224   0.10  0.224   0.10   0.10  0.224  0.224   0.72   0.10   \n",
      "3       0.224   0.10  0.224   0.10   0.10  0.224  0.224   0.72   0.10   \n",
      "4       0.100   0.10  0.100   0.10   0.10  0.100  0.100   0.10   0.10   \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "141356  0.930   0.93  0.930   0.93   0.93  0.930  0.930   0.93   0.93   \n",
      "141357    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "141358  0.930   0.93  0.930   0.93   0.93  0.930  0.930   0.93   0.93   \n",
      "141359    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "141360    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "              PARKING_ID2  \n",
      "0         cm31023000001_0  \n",
      "1         cm31023000001_1  \n",
      "2         cm31023000001_2  \n",
      "3         cm31023000001_3  \n",
      "4         cm31023000001_4  \n",
      "...                   ...  \n",
      "141356  pd31011500636_176  \n",
      "141357  pd31011500636_177  \n",
      "141358  pd31011500636_178  \n",
      "141359  pd31011500636_179  \n",
      "141360  pd31011500636_180  \n",
      "\n",
      "[141361 rows x 10 columns]\n",
      "<ipython-input-12-5f4d32fdd6c7>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[j] = m\n",
      "          03.25  03.26  03.27     03.29  03.30  03.31     04.01     04.02  \\\n",
      "0      0.816667    0.7    0.7  0.816667    1.0    0.9  0.816667  0.816667   \n",
      "1      0.816667    0.7    0.7  0.816667    1.0    0.9  0.816667  0.816667   \n",
      "2      0.816667    0.7    0.7  0.816667    1.0    0.9  0.816667  0.816667   \n",
      "3      0.800000    0.7    0.7  0.800000    0.9    0.9  0.800000  0.800000   \n",
      "4      0.816667    0.7    0.8  0.816667    0.8    1.0  0.816667  0.816667   \n",
      "...         ...    ...    ...       ...    ...    ...       ...       ...   \n",
      "79997       NaN    NaN    NaN       NaN    NaN    NaN       NaN       NaN   \n",
      "79998       NaN    NaN    NaN       NaN    NaN    NaN       NaN       NaN   \n",
      "79999       NaN    NaN    NaN       NaN    NaN    NaN       NaN       NaN   \n",
      "80000       NaN    NaN    NaN       NaN    NaN    NaN       NaN       NaN   \n",
      "80001       NaN    NaN    NaN       NaN    NaN    NaN       NaN       NaN   \n",
      "\n",
      "       04.03  04.04  PARKING_ID2  \n",
      "0        0.6    1.0     CM-002_0  \n",
      "1        0.6    1.0     CM-002_1  \n",
      "2        0.6    1.0     CM-002_2  \n",
      "3        0.6    1.0     CM-002_3  \n",
      "4        0.6    1.0     CM-002_4  \n",
      "...      ...    ...          ...  \n",
      "79997    NaN    NaN  PDL-061_176  \n",
      "79998    NaN    NaN  PDL-061_177  \n",
      "79999    NaN    NaN  PDL-061_178  \n",
      "80000    NaN    NaN  PDL-061_179  \n",
      "80001    NaN    NaN  PDL-061_180  \n",
      "\n",
      "[80002 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in basic_all_merge_byDay_path:\n",
    "    data = pd.read_csv(i)\n",
    "    data = data.sort_index(axis=1)\n",
    "    #print(data[data.isnull().T.any()].fillna(data[data.isnull().T.any()].mean(), axis=0))\n",
    "    #print(data)\n",
    "    #data_numpy = data.to_numpy()\n",
    "    #data = data.fillna(-111)\n",
    "    #data = data.replace(-111, np.nan)\n",
    "    for k in range(len(data)):\n",
    "        d = data.iloc[k]\n",
    "        #print(math.isnan(d[0]), d[0] ,d[1])\n",
    "        if (d.isnull().any()):\n",
    "            for j in d.index:\n",
    "                m = d[:-1].mean()\n",
    "                #print(\"d[j]: \", d[j])\n",
    "                #print(type(d[j]), d[j], type(j))\n",
    "                if ((j != \"PARKING_ID2\") and (math.isnan(d[j]))) :\n",
    "                    #print(type(d[j]))\n",
    "                    d[j] = m\n",
    "                    #print(\"d[j]2: \", d[j])\n",
    "            data.iloc[k] = d\n",
    "            #print(\"d2: \", d)\n",
    "    print(data)\n",
    "    data = data.fillna(method='ffill', axis=0)\n",
    "    data = data.sort_index(axis=1)\n",
    "    data.to_csv(i, index=False, mode=\"w\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}